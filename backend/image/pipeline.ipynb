{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dbcbe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in /home/coco/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302eaf52a2284445b6f9094dc523a223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_textline_ori), the model files will be automatically downloaded and saved in /home/coco/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5266ca1e800f40f8b64ca37747b794a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in /home/coco/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85d1127837b4a6592af205516e8c5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in /home/coco/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e30d12bf9942678987c4db46a2cb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import base64\n",
    "from scipy.ndimage import interpolation as inter\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "imgsz = 640\n",
    "\n",
    "model = YOLO('./TRAINING/runs/segment/train3/weights/best.pt')\n",
    "ocr = PaddleOCR(\n",
    "    ocr_version='PP-OCRv5',\n",
    "    use_doc_orientation_classify=True, \n",
    "    use_doc_unwarping=False, \n",
    "    use_textline_orientation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72e0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_skew(image, delta=1, limit=5):\n",
    "    def determine_score(arr, angle):\n",
    "        data = inter.rotate(arr, angle, reshape=False, order=0)\n",
    "        histogram = np.sum(data, axis=1, dtype=float)\n",
    "        score = np.sum((histogram[1:] - histogram[:-1]) ** 2, dtype=float)\n",
    "        return histogram, score\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    scores = []\n",
    "    angles = np.arange(-limit, limit + delta, delta)\n",
    "    for angle in angles:\n",
    "        histogram, score = determine_score(thresh, angle)\n",
    "        scores.append(score)\n",
    "    best_angle = angles[scores.index(max(scores))]\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, best_angle, 1.0)\n",
    "    corrected = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return best_angle, corrected\n",
    "\n",
    "def calculate_aspect_ratio(width, height):\n",
    "    gcd = math.gcd(int(width), int(height))\n",
    "    simplified_width = int(width) // gcd\n",
    "    simplified_height = int(height) // gcd\n",
    "    return f\"{simplified_width}:{simplified_height}\", simplified_width / simplified_height\n",
    "\n",
    "def aspect_ratio_distance(ratio, target_ratio=82/57):\n",
    "    return abs(ratio - target_ratio)\n",
    "\n",
    "def find_mask_corners(mask):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
    "        approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "        if len(approx) == 4:\n",
    "            return approx.reshape(4, 2).astype(np.float32)\n",
    "        else:\n",
    "            rect = cv2.minAreaRect(largest_contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            return box.astype(np.float32)\n",
    "    return None\n",
    "\n",
    "def evaluate_mask_shape(mask):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return 0\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
    "    approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "    shape_score = 0\n",
    "    if len(approx) == 4:\n",
    "        shape_score += 10\n",
    "    area = cv2.contourArea(largest_contour)\n",
    "    hull = cv2.convexHull(largest_contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    if hull_area > 0:\n",
    "        solidity = area / hull_area\n",
    "        shape_score += solidity * 5\n",
    "    perimeter = cv2.arcLength(largest_contour, True)\n",
    "    if perimeter > 0:\n",
    "        circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "        rectangularity = 1 - circularity\n",
    "        shape_score += rectangularity * 3\n",
    "    return shape_score\n",
    "\n",
    "def calculate_mask_area(mask):\n",
    "    return np.sum(mask)\n",
    "\n",
    "def is_four_sided_shape(mask):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return False\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
    "    approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "    return len(approx) == 4\n",
    "\n",
    "def check_minimum_width(mask, min_width=20):\n",
    "    mask_coords = np.where(mask)\n",
    "    if len(mask_coords[0]) > 0:\n",
    "        min_x, max_x = np.min(mask_coords[1]), np.max(mask_coords[1])\n",
    "        width = max_x - min_x + 1\n",
    "        return width >= min_width\n",
    "    return False\n",
    "\n",
    "def meets_mandatory_requirements(mask, max_aspect_distance=0.5):\n",
    "    if not is_four_sided_shape(mask):\n",
    "        return False, \"Not 4-sided\"\n",
    "    if not check_minimum_width(mask):\n",
    "        return False, \"Width < 20px\"\n",
    "    mask_coords = np.where(mask)\n",
    "    if len(mask_coords[0]) == 0:\n",
    "        return False, \"Empty mask\"\n",
    "    min_y, max_y = np.min(mask_coords[0]), np.max(mask_coords[0])\n",
    "    min_x, max_x = np.min(mask_coords[1]), np.max(mask_coords[1])\n",
    "    mask_width = max_x - min_x + 1\n",
    "    mask_height = max_y - min_y + 1\n",
    "    # aspect_str, aspect_float = calculate_aspect_ratio(mask_width, mask_height)\n",
    "    # distance = aspect_ratio_distance(aspect_float)\n",
    "    # if distance > max_aspect_distance:\n",
    "    #     return False, f\"Aspect ratio too far: {aspect_str}\"\n",
    "    return True, \"Valid\"\n",
    "\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=np.float32)\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9b3c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_boxes(ocr_results: List[dict]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Extract bounding boxes from OCR results\n",
    "    \n",
    "    Args:\n",
    "        ocr_results: List of OCR result dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing bounding box info for each page/image\n",
    "    \"\"\"\n",
    "    all_boxes = []\n",
    "    \n",
    "    for page_idx, result in enumerate(ocr_results):\n",
    "        # page_boxes = {\n",
    "        #     # 'page_index': page_idx,\n",
    "        #     'boxes': [],\n",
    "        #     # 'texts': result.get('rec_texts', []),\n",
    "        #     # 'scores': result.get('rec_scores', [])\n",
    "        # }\n",
    "        \n",
    "        # Method 1: Using rec_boxes (if available)\n",
    "        if 'rec_boxes' in result and len(result['rec_boxes']) > 0:\n",
    "            for i, box in enumerate(result['rec_boxes']):\n",
    "                # rec_boxes format: [x1, y1, x2, y2] or similar\n",
    "                bbox_info = {\n",
    "                    'bbox': box.tolist(),\n",
    "                    'text': result['rec_texts'][i] if i < len(result['rec_texts']) else '',\n",
    "                    'score': result['rec_scores'][i] if i < len(result['rec_scores']) else 0,\n",
    "                    'type': 'rec_box'\n",
    "                }\n",
    "                all_boxes.append(bbox_info)\n",
    "        \n",
    "        # Method 2: Using rec_polys (polygon format)\n",
    "        elif 'rec_polys' in result and len(result['rec_polys']) > 0:\n",
    "            for i, poly in enumerate(result['rec_polys']):\n",
    "                # Convert polygon to bounding box\n",
    "                x_coords = poly[:, 0]\n",
    "                y_coords = poly[:, 1]\n",
    "                x1, y1 = np.min(x_coords), np.min(y_coords)\n",
    "                x2, y2 = np.max(x_coords), np.max(y_coords)\n",
    "                \n",
    "                bbox_info = {\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'polygon': poly.tolist(),\n",
    "                    'text': result['rec_texts'][i] if i < len(result['rec_texts']) else '',\n",
    "                    'score': result['rec_scores'][i] if i < len(result['rec_scores']) else 0,\n",
    "                    'type': 'polygon'\n",
    "                }\n",
    "                all_boxes.append(bbox_info)\n",
    "        \n",
    "        # Method 3: Using dt_polys (detection polygons)\n",
    "        elif 'dt_polys' in result and len(result['dt_polys']) > 0:\n",
    "            for i, poly in enumerate(result['dt_polys']):\n",
    "                # Convert polygon to bounding box\n",
    "                x_coords = poly[:, 0]\n",
    "                y_coords = poly[:, 1]\n",
    "                x1, y1 = np.min(x_coords), np.min(y_coords)\n",
    "                x2, y2 = np.max(x_coords), np.max(y_coords)\n",
    "                \n",
    "                bbox_info = {\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'polygon': poly.tolist(),\n",
    "                    'text': result['rec_texts'][i] if i < len(result['rec_texts']) else '',\n",
    "                    'score': result['rec_scores'][i] if i < len(result['rec_scores']) else 0,\n",
    "                    'type': 'detection'\n",
    "                }\n",
    "                all_boxes.append(bbox_info)\n",
    "        \n",
    "        # all_boxes.append(page_boxes)\n",
    "    \n",
    "    return all_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "491571dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_data):\n",
    "    try:\n",
    "        nparr = np.frombuffer(base64.b64decode(img_data), np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        original_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = original_rgb.shape[:2]\n",
    "        \n",
    "        results = model(cv2.resize(img.copy(), (imgsz, imgsz)), verbose=False, conf=0.4, device='cuda')\n",
    "        ocr_results = []\n",
    "        \n",
    "        if results[0].masks is not None:\n",
    "\n",
    "            boxes = [[x1, y1, x2, y2, score] for x1, y1, x2, y2, score, _ in results[0].boxes.data.tolist()]\n",
    "            mask_indices = np.argsort([mask[0][0] for mask in results[0].masks.data.tolist()])\n",
    "            box_indices = np.argsort([box[0] for box in boxes])\n",
    "            index_mapping = dict(zip(box_indices, range(len(boxes))))\n",
    "            tracked_masks = [results[0].masks.data.tolist()[mask_indices[index_mapping[i]]] \n",
    "                            for i in range(len(boxes)) if i in index_mapping]\n",
    "\n",
    "            \n",
    "            for mask_idx, (box, mask) in enumerate(zip(boxes, tracked_masks)):\n",
    "                \n",
    "                xyxy = np.array(box[:4])\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                scale_x, scale_y = w / imgsz, h / imgsz\n",
    "                x1, y1, x2, y2 = int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y)\n",
    "                \n",
    "                padding = 50\n",
    "                x1_pad = max(0, x1 - padding)\n",
    "                y1_pad = max(0, y1 - padding)\n",
    "                x2_pad = min(w, x2 + padding)\n",
    "                y2_pad = min(h, y2 + padding)\n",
    "                \n",
    "                cropped_no_pad = original_rgb[y1:y2, x1:x2]\n",
    "                if cropped_no_pad.size == 0:\n",
    "                    continue\n",
    "                \n",
    "                mask_data = np.array(mask[:-2])\n",
    "                enhanced_mask = mask_data > 0.5\n",
    "                is_valid, reason = meets_mandatory_requirements(enhanced_mask)\n",
    "                \n",
    "                if is_valid:\n",
    "                    mask_coords = np.where(enhanced_mask)\n",
    "                    min_y, max_y = np.min(mask_coords[0]), np.max(mask_coords[0])\n",
    "                    min_x, max_x = np.min(mask_coords[1]), np.max(mask_coords[1])\n",
    "                    mask_width = max_x - min_x + 1\n",
    "                    mask_height = max_y - min_y + 1\n",
    "                    aspect_str, aspect_float = calculate_aspect_ratio(mask_width, mask_height)\n",
    "                    # distance = aspect_ratio_distance(aspect_float)\n",
    "                    shape_score = evaluate_mask_shape(enhanced_mask)\n",
    "                    area = calculate_mask_area(enhanced_mask)\n",
    "                    # valid_candidate = {'mask': enhanced_mask, 'image': original_rgb, 'name': 'full', 'distance': distance, 'shape_score': shape_score, 'area': area}\n",
    "                    valid_candidate = {'mask': enhanced_mask, 'image': original_rgb, 'name': 'full', 'shape_score': shape_score, 'area': area}\n",
    "                else:\n",
    "                    valid_candidate = None\n",
    "                \n",
    "                if valid_candidate is None:\n",
    "                    working_image = cv2.cvtColor(cropped_no_pad, cv2.COLOR_RGB2BGR)\n",
    "                else:\n",
    "                    # corners = find_mask_corners(valid_candidate['mask'])\n",
    "                    # if corners is not None:\n",
    "                    #     ordered_corners = order_points(corners)\n",
    "                    #     width = int(max(np.linalg.norm(ordered_corners[1] - ordered_corners[0]), np.linalg.norm(ordered_corners[2] - ordered_corners[3])))\n",
    "                    #     height = int(max(np.linalg.norm(ordered_corners[3] - ordered_corners[0]), np.linalg.norm(ordered_corners[2] - ordered_corners[1])))\n",
    "                    #     dst_corners = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]], dtype=np.float32)\n",
    "                    #     M = cv2.getPerspectiveTransform(ordered_corners, dst_corners)\n",
    "                    #     warped = cv2.warpPerspective(valid_candidate['image'], M, (width, height))\n",
    "                    #     working_image = cv2.cvtColor(warped, cv2.COLOR_RGB2BGR)\n",
    "                    # else:\n",
    "                    working_image = cv2.cvtColor(cropped_no_pad, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                _, corrected_bgr = correct_skew(working_image)\n",
    "                final_gray = cv2.cvtColor(corrected_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                _, thresholded = cv2.threshold(final_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                \n",
    "                try:\n",
    "                    final_img = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)\n",
    "                    result = ocr.predict(final_img)\n",
    "                    if result and result[0]:\n",
    "                        ocr_texts = result[0].get('rec_texts', [])\n",
    "                        confidences = result[0].get('rec_scores', [])\n",
    "                        rec_polys = result[0].get('rec_polys', [])\n",
    "                        rec_boxes = result[0].get('rec_boxes', [])\n",
    "                        dt_polys = result[0].get('dt_polys', [])\n",
    "                        # print(rec_boxes)\n",
    "                        # print('-'*8)\n",
    "\n",
    "                        # print(extract_bounding_boxes(result))\n",
    "                        \n",
    "                        if ocr_texts:\n",
    "                            ocr_results.extend(extract_bounding_boxes(result))\n",
    "                            # ocr_text = \" \".join(ocr_texts)\n",
    "                            # avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n",
    "\n",
    "                            # for ocr_text, conf in zip(ocr_texts, confidences):\n",
    "                            #     # ocr_text = re.sub(r'[^A-Za-z0-9\\s]', '', ocr_text).strip()\n",
    "                            #     if len(ocr_text) >= 3:\n",
    "                            #         ocr_results.extend(extract_bounding_boxes(result))\n",
    "                                    # ocr_results.append({'text': ocr_text, 'confidence': conf, 'bbox': [x1, y1, x2, y2]})\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        ocr_text = \"\"\n",
    "                        avg_confidence = 0\n",
    "                except Exception as e:\n",
    "                    ocr_text = f\"ERROR: {str(e)[:30]}\"\n",
    "                    avg_confidence = 0\n",
    "\n",
    "                # ocr_results.append({'text': ocr_text, 'confidence': avg_confidence,})\n",
    "        \n",
    "        return {'success': True, 'results': ocr_results}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'success': False, 'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9761ab9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_412302/1324014784.py:3: DeprecationWarning: Please import `rotate` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  data = inter.rotate(arr, angle, reshape=False, order=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'results': [{'bbox': [64, 15, 73, 25],\n",
       "   'text': '￥',\n",
       "   'score': 0.528009831905365,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [46, 33, 55, 42],\n",
       "   'text': '★',\n",
       "   'score': 0.3508351147174835,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [81, 32, 91, 42],\n",
       "   'text': '★',\n",
       "   'score': 0.8847569227218628,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [52, 56, 61, 66],\n",
       "   'text': '★',\n",
       "   'score': 0.6082736253738403,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [77, 58, 84, 65],\n",
       "   'text': '1',\n",
       "   'score': 0.10120319575071335,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [18, 232, 207, 272],\n",
       "   'text': 'NAME SURNAME',\n",
       "   'score': 0.98024582862854,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [20, 267, 166, 291],\n",
       "   'text': 'JOB POSITION',\n",
       "   'score': 0.9643695950508118,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [17, 302, 134, 322],\n",
       "   'text': '+0123 456 789',\n",
       "   'score': 0.9298632740974426,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [16, 343, 220, 360],\n",
       "   'text': 'name@companyname.com',\n",
       "   'score': 0.982434868812561,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [13, 383, 204, 403],\n",
       "   'text': 'www.companyname.com',\n",
       "   'score': 0.9939028024673462,\n",
       "   'type': 'rec_box'},\n",
       "  {'bbox': [10, 425, 131, 445],\n",
       "   'text': 'address line here',\n",
       "   'score': 0.9657682776451111,\n",
       "   'type': 'rec_box'}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_path = './datasets/valid/images/ds1_0000_jpg.rf.4eae7fa15bbb753677b864a8c8437835.jpg'\n",
    "# img_path = './6163206443046652006.jpg'\n",
    "img_path = './TRAINING/sg-11134207-7rcda-lri9ci2lu1wo0e.jpg'\n",
    "\n",
    "img = base64.b64encode(open(img_path, 'rb').read()).decode('utf-8')\n",
    "\n",
    "process_image(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17cf7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = './sg-11134207-7rcda-lri9ci2lu1wo0e.jpg'\n",
    "# results = model(image_path)\n",
    "\n",
    "# img = cv2.imread(image_path)\n",
    "# img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(img_rgb)\n",
    "# plt.title('Original Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# annotated_img = results[0].plot()\n",
    "# annotated_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(annotated_rgb)\n",
    "# plt.title('YOLO Segmentation Results')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# for result in results:\n",
    "#     print(f\"Detected {len(result.boxes)} objects\")\n",
    "#     if result.masks is not None:\n",
    "#         print(f\"Generated {len(result.masks)} masks\")\n",
    "#     print(f\"Confidence scores: {result.boxes.conf.tolist()}\")\n",
    "#     print(f\"Class IDs: {result.boxes.cls.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c69fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5f497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
