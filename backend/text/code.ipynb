{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3888c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tenseal cryptography -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156f2a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tenseal as ts\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import hashlib\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    import albumentations as A\n",
    "except ImportError:\n",
    "    print(\"albumentations not installed, using basic transforms\")\n",
    "    A = None\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Ultralytics YOLO imports (optional for demo)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    from ultralytics.models.yolo.segment import SegmentationTrainer\n",
    "    from ultralytics.models.yolo.detect import DetectionTrainer\n",
    "    from ultralytics.utils import ops\n",
    "    import yaml\n",
    "    YOLO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Ultralytics YOLO not installed - running in demo mode\")\n",
    "    YOLO_AVAILABLE = False\n",
    "    \n",
    "    # Create dummy YOLO class for demo\n",
    "    class YOLO:\n",
    "        def __init__(self, model_path):\n",
    "            self.ckpt_path = model_path\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            return \"simulated_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class YOLOHEConfig:\n",
    "    \"\"\"Configuration for YOLO homomorphic encryption\"\"\"\n",
    "    poly_modulus_degree: int = 16384\n",
    "    coeff_mod_bit_sizes: List[int] = None\n",
    "    scale: float = 2.0**30\n",
    "    yolo_input_size: int = 640  # Standard YOLO input size\n",
    "    tile_size: Tuple[int, int] = (80, 80)  # Divide 640x640 into 8x8 tiles\n",
    "    compression_ratio: float = 0.05  # Heavy compression for HE\n",
    "    preserve_aspect_ratio: bool = True\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.coeff_mod_bit_sizes is None:\n",
    "            self.coeff_mod_bit_sizes = [60, 40, 40, 40, 60]\n",
    "\n",
    "# class EncryptedYOLODataset(Dataset):\n",
    "#     \"\"\"Dataset for YOLO with encrypted images\"\"\"\n",
    "    \n",
    "#     def __init__(self, image_paths: List[str], annotation_paths: List[str],\n",
    "#                  encryption_system, model_type: str = \"segment\", transform=None):\n",
    "#         self.image_paths = image_paths\n",
    "#         self.annotation_paths = annotation_paths\n",
    "#         self.encryption_system = encryption_system\n",
    "#         self.model_type = model_type  # \"detect\" or \"segment\"\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "    \n",
    "#     def _load_yolo_annotations(self, ann_path: str, img_shape: Tuple[int, int]):\n",
    "#         \"\"\"Load YOLO format annotations\"\"\"\n",
    "#         annotations = []\n",
    "#         if Path(ann_path).exists():\n",
    "#             with open(ann_path, 'r') as f:\n",
    "#                 for line in f:\n",
    "#                     parts = line.strip().split()\n",
    "#                     if len(parts) >= 5:\n",
    "#                         class_id = int(parts[0])\n",
    "#                         # Convert normalized coordinates to pixel coordinates\n",
    "#                         x_center = float(parts[1]) * img_shape[1]\n",
    "#                         y_center = float(parts[2]) * img_shape[0]\n",
    "#                         width = float(parts[3]) * img_shape[1]\n",
    "#                         height = float(parts[4]) * img_shape[0]\n",
    "                        \n",
    "#                         # For segmentation, parts[5:] would contain polygon points\n",
    "#                         bbox = [x_center - width/2, y_center - height/2, width, height]\n",
    "                        \n",
    "#                         annotation = {\n",
    "#                             'class_id': class_id,\n",
    "#                             'bbox': bbox,\n",
    "#                             'polygon': parts[5:] if len(parts) > 5 else None\n",
    "#                         }\n",
    "#                         annotations.append(annotation)\n",
    "        \n",
    "#         return annotations\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         # Load image\n",
    "#         image = cv2.imread(self.image_paths[idx])\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         original_shape = image.shape\n",
    "        \n",
    "#         # Resize to YOLO input size\n",
    "#         image_resized = cv2.resize(image, (self.encryption_system.config.yolo_input_size,\n",
    "#                                           self.encryption_system.config.yolo_input_size))\n",
    "        \n",
    "#         # Load annotations\n",
    "#         annotations = self._load_yolo_annotations(self.annotation_paths[idx], original_shape[:2])\n",
    "        \n",
    "#         # Apply transforms if specified\n",
    "#         if self.transform:\n",
    "#             augmented = self.transform(image=image_resized)\n",
    "#             image_resized = augmented['image']\n",
    "        \n",
    "#         # Encrypt image\n",
    "#         encrypted_data = self.encryption_system.encrypt_yolo_image(image_resized)\n",
    "        \n",
    "#         return {\n",
    "#             'encrypted_tiles': encrypted_data['encrypted_tiles'],\n",
    "#             'tile_grid_shape': encrypted_data['grid_shape'],\n",
    "#             'annotations': annotations,\n",
    "#             'original_shape': original_shape,\n",
    "#             'image_path': self.image_paths[idx],\n",
    "#             'encrypted_metadata': encrypted_data['metadata']\n",
    "#         }\n",
    "\n",
    "class YOLOImageEncryptionSystem:\n",
    "    \"\"\"Specialized encryption system for YOLO models\"\"\"\n",
    "    \n",
    "    def __init__(self, config: YOLOHEConfig = None):\n",
    "        self.config = config or YOLOHEConfig()\n",
    "        self.he_context = None\n",
    "        self.encryption_mappings = {}\n",
    "        self.fernet_key = Fernet.generate_key()\n",
    "        self.fernet = Fernet(self.fernet_key)\n",
    "        \n",
    "    def setup_he_context(self) -> ts.Context:\n",
    "        \"\"\"Initialize CKKS context optimized for YOLO images\"\"\"\n",
    "        logger.info(\"Setting up CKKS context for YOLO...\")\n",
    "        \n",
    "        context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=self.config.poly_modulus_degree,\n",
    "            coeff_mod_bit_sizes=self.config.coeff_mod_bit_sizes\n",
    "        )\n",
    "        \n",
    "        context.generate_galois_keys()\n",
    "        context.generate_relin_keys()\n",
    "        context.global_scale = self.config.scale\n",
    "        \n",
    "        self.he_context = context\n",
    "        logger.info(\"CKKS context initialized for YOLO processing\")\n",
    "        return context\n",
    "    \n",
    "    def encrypt_yolo_image(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"Encrypt image for YOLO processing\"\"\"\n",
    "        if not self.he_context:\n",
    "            self.setup_he_context()\n",
    "        \n",
    "        # Ensure image is YOLO size\n",
    "        target_size = self.config.yolo_input_size\n",
    "        if image.shape[:2] != (target_size, target_size):\n",
    "            image = cv2.resize(image, (target_size, target_size))\n",
    "        \n",
    "        # Split into tiles\n",
    "        tiles = self._split_into_yolo_tiles(image)\n",
    "        \n",
    "        # Encrypt each tile\n",
    "        encrypted_tiles = []\n",
    "        metadata = []\n",
    "        \n",
    "        for i, tile in enumerate(tiles):\n",
    "            # Extract features and compress\n",
    "            features = self._extract_tile_features(tile)\n",
    "            \n",
    "            # Encrypt with CKKS\n",
    "            encrypted_vector = ts.ckks_vector(self.he_context, features)\n",
    "            serialized = encrypted_vector.serialize()\n",
    "            \n",
    "            encrypted_tiles.append(serialized)\n",
    "            metadata.append({\n",
    "                'tile_id': i,\n",
    "                'position': self._get_tile_position(i),\n",
    "                'feature_dim': len(features)\n",
    "            })\n",
    "        \n",
    "        grid_h = target_size // self.config.tile_size[0]\n",
    "        grid_w = target_size // self.config.tile_size[1]\n",
    "        \n",
    "        return {\n",
    "            'encrypted_tiles': encrypted_tiles,\n",
    "            'grid_shape': (grid_h, grid_w),\n",
    "            'metadata': metadata,\n",
    "            'encryption_id': hashlib.md5(str(tiles).encode()).hexdigest()[:16]\n",
    "        }\n",
    "    \n",
    "    def _split_into_yolo_tiles(self, image: np.ndarray) -> List[np.ndarray]:\n",
    "        \"\"\"Split YOLO-sized image into tiles\"\"\"\n",
    "        h, w, c = image.shape\n",
    "        tile_h, tile_w = self.config.tile_size\n",
    "        \n",
    "        tiles = []\n",
    "        for i in range(0, h, tile_h):\n",
    "            for j in range(0, w, tile_w):\n",
    "                tile = image[i:i+tile_h, j:j+tile_w]\n",
    "                \n",
    "                # Pad if necessary (edge tiles)\n",
    "                if tile.shape[0] < tile_h or tile.shape[1] < tile_w:\n",
    "                    padded_tile = np.zeros((tile_h, tile_w, c), dtype=image.dtype)\n",
    "                    padded_tile[:tile.shape[0], :tile.shape[1]] = tile\n",
    "                    tile = padded_tile\n",
    "                \n",
    "                tiles.append(tile)\n",
    "        \n",
    "        return tiles\n",
    "    \n",
    "    def _get_tile_position(self, tile_idx: int) -> Tuple[int, int]:\n",
    "        \"\"\"Get grid position of tile\"\"\"\n",
    "        grid_w = self.config.yolo_input_size // self.config.tile_size[1]\n",
    "        row = tile_idx // grid_w\n",
    "        col = tile_idx % grid_w\n",
    "        return (row, col)\n",
    "    \n",
    "    def _extract_tile_features(self, tile: np.ndarray) -> List[float]:\n",
    "        \"\"\"Extract features from tile for HE (optimized for YOLO)\"\"\"\n",
    "        # Ensure proper data type for OpenCV\n",
    "        tile = tile.astype(np.uint8)\n",
    "        features = []\n",
    "        \n",
    "        # Color channel statistics\n",
    "        for c in range(min(3, tile.shape[2])):  # Handle grayscale or RGB\n",
    "            channel = tile[:, :, c] if len(tile.shape) == 3 else tile\n",
    "            features.extend([\n",
    "                float(np.mean(channel)) / 255.0,\n",
    "                float(np.std(channel)) / 255.0,\n",
    "                float(np.median(channel)) / 255.0\n",
    "            ])\n",
    "        \n",
    "        # Convert to grayscale safely\n",
    "        if len(tile.shape) == 3 and tile.shape[2] == 3:\n",
    "            gray = cv2.cvtColor(tile, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = tile if len(tile.shape) == 2 else tile[:, :, 0]\n",
    "        \n",
    "        gray = gray.astype(np.uint8)\n",
    "        \n",
    "        # Edge features (important for object detection)\n",
    "        try:\n",
    "            edges = cv2.Canny(gray, 50, 150)\n",
    "            edge_density = float(np.sum(edges > 0)) / edges.size\n",
    "            features.append(edge_density)\n",
    "        except:\n",
    "            features.append(0.0)  # Fallback\n",
    "        \n",
    "        # Corner features\n",
    "        try:\n",
    "            corners = cv2.goodFeaturesToTrack(gray, 25, 0.01, 10)\n",
    "            corner_count = len(corners) if corners is not None else 0\n",
    "            features.append(float(corner_count) / 25.0)  # Normalize\n",
    "        except:\n",
    "            features.append(0.0)  # Fallback\n",
    "        \n",
    "        # Texture features (simplified)\n",
    "        try:\n",
    "            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            texture_strength = float(np.mean(np.sqrt(grad_x**2 + grad_y**2))) / 255.0\n",
    "            features.append(texture_strength)\n",
    "        except:\n",
    "            features.append(0.0)  # Fallback\n",
    "        \n",
    "        # Apply compression\n",
    "        compression_step = max(1, int(1 / self.config.compression_ratio))\n",
    "        if len(features) > compression_step:\n",
    "            features = features[::compression_step]\n",
    "        \n",
    "        return features\n",
    "\n",
    "class PrivacyPreservingYOLO:\n",
    "    \"\"\"Privacy-preserving wrapper for YOLO models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = \"yolov8n-seg.pt\", \n",
    "                 encryption_system: YOLOImageEncryptionSystem = None, \n",
    "                 demo_mode: bool = True):\n",
    "        self.model_path = model_path\n",
    "        self.demo_mode = demo_mode\n",
    "        self.encryption_system = encryption_system or YOLOImageEncryptionSystem()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize YOLO model (or simulate for demo)\n",
    "        if not demo_mode:\n",
    "            try:\n",
    "                self.model = YOLO(model_path)\n",
    "            except ImportError:\n",
    "                logger.warning(\"Ultralytics not installed, running in demo mode\")\n",
    "                self.demo_mode = True\n",
    "                self.model = None\n",
    "        else:\n",
    "            self.model = None\n",
    "        \n",
    "        # Privacy-preserving adapter network\n",
    "        self.privacy_adapter = self._build_privacy_adapter()\n",
    "        \n",
    "    def _build_privacy_adapter(self) -> nn.Module:\n",
    "        \"\"\"Build adapter network to process encrypted features\"\"\"\n",
    "        # Estimate feature dimension from encryption system\n",
    "        dummy_tile = np.random.randint(0, 255, (*self.encryption_system.config.tile_size, 3))\n",
    "        feature_dim = len(self.encryption_system._extract_tile_features(dummy_tile))\n",
    "        \n",
    "        adapter = nn.Sequential(\n",
    "            # Decrypt and process encrypted features\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Map to YOLO-compatible features\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            # Output layer (maps to RGB tile representation)\n",
    "            nn.Linear(512, self.encryption_system.config.tile_size[0] * \n",
    "                           self.encryption_system.config.tile_size[1] * 3),\n",
    "            nn.Sigmoid()  # Normalize to [0,1]\n",
    "        )\n",
    "        \n",
    "        return adapter.to(self.device)\n",
    "    \n",
    "    def encrypt_and_predict(self, image: np.ndarray, confidence: float = 0.25, \n",
    "                           privacy_level: int = 2) -> Dict:\n",
    "        \"\"\"Perform YOLO prediction on encrypted image\"\"\"\n",
    "        \n",
    "        if privacy_level == 1:\n",
    "            # Level 1: Light encryption with direct YOLO inference\n",
    "            return self._predict_level_1(image, confidence)\n",
    "        elif privacy_level == 2:\n",
    "            # Level 2: Feature encryption with adapter network\n",
    "            return self._predict_level_2(image, confidence)\n",
    "        else:\n",
    "            # Level 3: Full homomorphic encryption\n",
    "            return self._predict_level_3(image, confidence)\n",
    "    \n",
    "    # def _predict_level_1(self, image: np.ndarray, confidence: float) -> Dict:\n",
    "    #     \"\"\"Level 1: Format-preserving encryption + standard YOLO\"\"\"\n",
    "    #     # Apply format-preserving encryption (pixel shuffling)\n",
    "    #     encrypted_image = self._format_preserving_encrypt(image)\n",
    "        \n",
    "    #     # Run YOLO on encrypted image (or simulate)\n",
    "    #     if self.demo_mode:\n",
    "    #         # Simulate YOLO results for demo\n",
    "    #         results = self._simulate_yolo_results(encrypted_image.shape)\n",
    "    #     else:\n",
    "    #         results = self.model(encrypted_image, conf=confidence, verbose=False)\n",
    "        \n",
    "    #     return {\n",
    "    #         'privacy_level': 1,\n",
    "    #         'results': results,\n",
    "    #         'encrypted_image_shape': encrypted_image.shape,\n",
    "    #         'encryption_overhead': 'minimal'\n",
    "    #     }\n",
    "    \n",
    "    # def _predict_level_2(self, image: np.ndarray, confidence: float) -> Dict:\n",
    "    #     \"\"\"Level 2: Hybrid approach with encrypted features\"\"\"\n",
    "    #     # Encrypt image tiles\n",
    "    #     encrypted_data = self.encryption_system.encrypt_yolo_image(image)\n",
    "        \n",
    "    #     # Process encrypted tiles through adapter\n",
    "    #     reconstructed_image = self._reconstruct_from_encrypted_tiles(encrypted_data)\n",
    "        \n",
    "    #     # Run YOLO on reconstructed image (or simulate)\n",
    "    #     if self.demo_mode:\n",
    "    #         results = self._simulate_yolo_results(reconstructed_image.shape)\n",
    "    #     else:\n",
    "    #         results = self.model(reconstructed_image, conf=confidence, verbose=False)\n",
    "        \n",
    "    #     return {\n",
    "    #         'privacy_level': 2,\n",
    "    #         'results': results,\n",
    "    #         'encrypted_tiles_count': len(encrypted_data['encrypted_tiles']),\n",
    "    #         'reconstruction_quality': self._calculate_reconstruction_quality(image, reconstructed_image)\n",
    "    #     }\n",
    "    \n",
    "    def _predict_level_3(self, image: np.ndarray, confidence: float) -> Dict:\n",
    "        \"\"\"Level 3: Full homomorphic encryption with secure computation\"\"\"\n",
    "        # This is the most complex case - simplified implementation\n",
    "        encrypted_data = self.encryption_system.encrypt_yolo_image(image)\n",
    "        \n",
    "        # In a real implementation, you'd perform homomorphic operations\n",
    "        # on the encrypted features to compute YOLO-like outputs\n",
    "        # For demo, we'll decrypt for inference but track privacy cost\n",
    "        \n",
    "        reconstructed_image = self._reconstruct_from_encrypted_tiles(encrypted_data)\n",
    "        \n",
    "        if self.demo_mode:\n",
    "            results = self._simulate_yolo_results(reconstructed_image.shape)\n",
    "        else:\n",
    "            results = self.model(reconstructed_image, conf=confidence, verbose=False)\n",
    "        \n",
    "        return {\n",
    "            'privacy_level': 3,\n",
    "            'results': results,\n",
    "            'privacy_cost': 'high',\n",
    "            'secure_computation': True,\n",
    "            'encrypted_inference': True\n",
    "        }\n",
    "    \n",
    "    def _simulate_yolo_results(self, image_shape: Tuple[int, int, int]) -> Dict:\n",
    "        \"\"\"Simulate YOLO results for demo purposes\"\"\"\n",
    "        h, w, c = image_shape\n",
    "        num_detections = np.random.randint(1, 5)\n",
    "        \n",
    "        # Simulate bounding boxes\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for _ in range(num_detections):\n",
    "            x1 = np.random.randint(0, w//2)\n",
    "            y1 = np.random.randint(0, h//2)\n",
    "            x2 = np.random.randint(x1 + 20, w)\n",
    "            y2 = np.random.randint(y1 + 20, h)\n",
    "            \n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            confidences.append(np.random.random() * 0.7 + 0.3)  # 0.3-1.0\n",
    "            class_ids.append(np.random.randint(0, 80))  # COCO has 80 classes\n",
    "        \n",
    "        # Simulate segmentation masks\n",
    "        masks = []\n",
    "        for bbox in boxes:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            # Create simple elliptical mask in bbox\n",
    "            center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            axes = ((x2 - x1) // 2, (y2 - y1) // 2)\n",
    "            cv2.ellipse(mask, (center_x, center_y), axes, 0, 0, 360, 255, -1)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        return {\n",
    "            'boxes': np.array(boxes),\n",
    "            'confidences': np.array(confidences),\n",
    "            'class_ids': np.array(class_ids),\n",
    "            'masks': masks,\n",
    "            'num_detections': num_detections\n",
    "        }\n",
    "    \n",
    "    def _format_preserving_encrypt(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Simple format-preserving encryption via pixel permutation\"\"\"\n",
    "        h, w, c = image.shape\n",
    "        \n",
    "        # Create deterministic permutation based on secret key\n",
    "        np.random.seed(42)  # In production, use actual secret key\n",
    "        \n",
    "        encrypted_image = image.copy()\n",
    "        for channel in range(c):\n",
    "            flat_channel = encrypted_image[:, :, channel].flatten()\n",
    "            perm_indices = np.random.permutation(len(flat_channel))\n",
    "            encrypted_image[:, :, channel] = flat_channel[perm_indices].reshape(h, w)\n",
    "        \n",
    "        return encrypted_image\n",
    "    \n",
    "    def _reconstruct_from_encrypted_tiles(self, encrypted_data: Dict) -> np.ndarray:\n",
    "        \"\"\"Reconstruct image from encrypted tiles using adapter network\"\"\"\n",
    "        encrypted_tiles = encrypted_data['encrypted_tiles']\n",
    "        grid_shape = encrypted_data['grid_shape']\n",
    "        \n",
    "        self.privacy_adapter.eval()\n",
    "        reconstructed_tiles = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for encrypted_tile_data in encrypted_tiles:\n",
    "                # Decrypt tile features\n",
    "                encrypted_vector = ts.lazy_ckks_vector_from(encrypted_tile_data)\n",
    "                encrypted_vector.link_context(self.encryption_system.he_context)\n",
    "                decrypted_features = encrypted_vector.decrypt()\n",
    "                \n",
    "                # Convert to tensor and process through adapter\n",
    "                feature_tensor = torch.FloatTensor(decrypted_features).unsqueeze(0).to(self.device)\n",
    "                reconstructed_flat = self.privacy_adapter(feature_tensor)\n",
    "                \n",
    "                # Reshape to tile\n",
    "                tile_h, tile_w = self.encryption_system.config.tile_size\n",
    "                reconstructed_tile = reconstructed_flat.view(tile_h, tile_w, 3)\n",
    "                reconstructed_tile = (reconstructed_tile * 255).cpu().numpy().astype(np.uint8)\n",
    "                reconstructed_tiles.append(reconstructed_tile)\n",
    "        \n",
    "        # Reassemble tiles into full image\n",
    "        return self._assemble_tiles(reconstructed_tiles, grid_shape)\n",
    "    \n",
    "    def _assemble_tiles(self, tiles: List[np.ndarray], grid_shape: Tuple[int, int]) -> np.ndarray:\n",
    "        \"\"\"Reassemble tiles into full image\"\"\"\n",
    "        grid_h, grid_w = grid_shape\n",
    "        tile_h, tile_w = self.encryption_system.config.tile_size\n",
    "        \n",
    "        full_image = np.zeros((grid_h * tile_h, grid_w * tile_w, 3), dtype=np.uint8)\n",
    "        \n",
    "        for idx, tile in enumerate(tiles):\n",
    "            row = idx // grid_w\n",
    "            col = idx % grid_w\n",
    "            \n",
    "            start_h = row * tile_h\n",
    "            start_w = col * tile_w\n",
    "            \n",
    "            full_image[start_h:start_h+tile_h, start_w:start_w+tile_w] = tile\n",
    "        \n",
    "        # Crop to YOLO input size if needed\n",
    "        target_size = self.encryption_system.config.yolo_input_size\n",
    "        return full_image[:target_size, :target_size]\n",
    "    \n",
    "    def _calculate_reconstruction_quality(self, original: np.ndarray, \n",
    "                                        reconstructed: np.ndarray) -> Dict:\n",
    "        \"\"\"Calculate reconstruction quality metrics\"\"\"\n",
    "        # Resize reconstructed to match original if needed\n",
    "        if original.shape != reconstructed.shape:\n",
    "            reconstructed = cv2.resize(reconstructed, (original.shape[1], original.shape[0]))\n",
    "        \n",
    "        mse = np.mean((original.astype(float) - reconstructed.astype(float)) ** 2)\n",
    "        psnr = 20 * np.log10(255.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "        \n",
    "        return {\n",
    "            'mse': float(mse),\n",
    "            'psnr': float(psnr),\n",
    "            'ssim': self._calculate_ssim(original, reconstructed)\n",
    "        }\n",
    "    \n",
    "    def _calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "        \"\"\"Calculate SSIM (simplified version)\"\"\"\n",
    "        # Convert to grayscale safely\n",
    "        if len(img1.shape) == 3:\n",
    "            gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "            gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray1, gray2 = img1, img2\n",
    "        \n",
    "        # Calculate means\n",
    "        mu1 = np.mean(gray1)\n",
    "        mu2 = np.mean(gray2)\n",
    "        \n",
    "        # Calculate variances and covariance\n",
    "        var1 = np.var(gray1)\n",
    "        var2 = np.var(gray2)\n",
    "        covar = np.mean((gray1 - mu1) * (gray2 - mu2))\n",
    "        \n",
    "        # SSIM calculation\n",
    "        c1 = (0.01 * 255) ** 2\n",
    "        c2 = (0.03 * 255) ** 2\n",
    "        \n",
    "        ssim = ((2 * mu1 * mu2 + c1) * (2 * covar + c2)) / \\\n",
    "               ((mu1**2 + mu2**2 + c1) * (var1 + var2 + c2))\n",
    "        \n",
    "        return float(ssim)\n",
    "\n",
    "class FederatedYOLOTrainer:\n",
    "    \"\"\"Federated learning trainer for YOLO with privacy preservation\"\"\"\n",
    "    \n",
    "    def __init__(self, model_config: str = \"yolov8n-seg.yaml\", num_clients: int = 5, demo_mode: bool = True):\n",
    "        self.model_config = model_config\n",
    "        self.num_clients = num_clients\n",
    "        self.demo_mode = demo_mode\n",
    "        self.encryption_system = YOLOImageEncryptionSystem()\n",
    "        \n",
    "        # Initialize models (or simulate for demo)\n",
    "        if not demo_mode:\n",
    "            try:\n",
    "                self.global_model = YOLO(model_config)\n",
    "                self.client_models = [YOLO(model_config) for _ in range(num_clients)]\n",
    "            except ImportError:\n",
    "                logger.warning(\"Ultralytics not installed, running in demo mode\")\n",
    "                self.demo_mode = True\n",
    "        \n",
    "        if self.demo_mode:\n",
    "            # Simulate model states for demo\n",
    "            self.global_model = self._create_dummy_model_state()\n",
    "            self.client_models = [self._create_dummy_model_state() for _ in range(num_clients)]\n",
    "        \n",
    "        # Differential privacy parameters\n",
    "        self.privacy_budget = 1.0\n",
    "        self.noise_multiplier = 1.0\n",
    "    \n",
    "    def _create_dummy_model_state(self) -> Dict:\n",
    "        \"\"\"Create dummy model state for demo\"\"\"\n",
    "        return {\n",
    "            'conv1.weight': torch.randn(64, 3, 3, 3),\n",
    "            'conv1.bias': torch.randn(64),\n",
    "            'fc.weight': torch.randn(80, 1000),  # 80 COCO classes\n",
    "            'fc.bias': torch.randn(80)\n",
    "        }\n",
    "        \n",
    "    def setup_client_data(self, data_splits: List[Dict]):\n",
    "        \"\"\"Setup data for each federated client\"\"\"\n",
    "        self.client_datasets = []\n",
    "        \n",
    "        for client_id, data_split in enumerate(data_splits):\n",
    "            # Create encrypted dataset for client\n",
    "            transform = A.Compose([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.RandomBrightnessContrast(p=0.3),\n",
    "                A.RandomRotate90(p=0.5)\n",
    "            ])\n",
    "            \n",
    "            dataset = EncryptedYOLODataset(\n",
    "                data_split['images'],\n",
    "                data_split['annotations'], \n",
    "                self.encryption_system,\n",
    "                transform=transform\n",
    "            )\n",
    "            \n",
    "            self.client_datasets.append(dataset)\n",
    "            \n",
    "        logger.info(f\"Setup data for {len(data_splits)} federated clients\")\n",
    "    \n",
    "    def train_federated_round(self, round_num: int, local_epochs: int = 5) -> Dict:\n",
    "        \"\"\"Execute one round of federated training\"\"\"\n",
    "        logger.info(f\"Starting federated round {round_num}\")\n",
    "        \n",
    "        if self.demo_mode:\n",
    "            # Simulate federated training for demo\n",
    "            print(f\"  Simulating client training...\")\n",
    "            for client_id in range(self.num_clients):\n",
    "                print(f\"    Client {client_id + 1}: Training on encrypted data...\")\n",
    "                # Simulate training time\n",
    "                import time\n",
    "                time.sleep(0.1)  # Brief pause for demo\n",
    "            \n",
    "            print(f\"  Aggregating {self.num_clients} client updates with privacy...\")\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            return {\n",
    "                'round': round_num,\n",
    "                'participating_clients': self.num_clients,\n",
    "                'local_epochs': local_epochs,\n",
    "                'privacy_budget_used': 0.1,\n",
    "                'aggregation_noise_added': True\n",
    "            }\n",
    "        \n",
    "        # Real federated training (when not in demo mode)\n",
    "        global_weights = self.global_model.model.state_dict() if hasattr(self.global_model, 'model') else self.global_model\n",
    "        client_weights = []\n",
    "        \n",
    "        for client_id in range(self.num_clients):\n",
    "            logger.info(f\"Training client {client_id + 1}/{self.num_clients}\")\n",
    "            \n",
    "            # Load global weights\n",
    "            if hasattr(self.client_models[client_id], 'model'):\n",
    "                self.client_models[client_id].model.load_state_dict(global_weights)\n",
    "            \n",
    "            # Train client model\n",
    "            client_weight = self._train_client(client_id, local_epochs)\n",
    "            client_weights.append(client_weight)\n",
    "        \n",
    "        # Aggregate client updates with privacy\n",
    "        self._secure_aggregate(client_weights)\n",
    "        \n",
    "        return {\n",
    "            'round': round_num,\n",
    "            'participating_clients': self.num_clients,\n",
    "            'local_epochs': local_epochs\n",
    "        }\n",
    "    \n",
    "    def _train_client(self, client_id: int, epochs: int) -> Dict:\n",
    "        \"\"\"Train single client with differential privacy\"\"\"\n",
    "        if self.demo_mode:\n",
    "            # Simulate training with privacy noise\n",
    "            simulated_weights = {}\n",
    "            for key in ['conv1.weight', 'conv1.bias', 'fc.weight', 'fc.bias']:\n",
    "                base_shape = self.client_models[client_id][key].shape\n",
    "                noise = torch.normal(0, self.noise_multiplier * 0.01, base_shape)\n",
    "                simulated_weights[key] = self.client_models[client_id][key] + noise\n",
    "            return simulated_weights\n",
    "        \n",
    "        # Real client training when ultralytics is available\n",
    "        client_model = self.client_models[client_id]\n",
    "        \n",
    "        # Create temporary dataset config for YOLO training\n",
    "        temp_config = self._create_temp_yolo_config(client_id)\n",
    "        \n",
    "        # For demo purposes, we'll simulate training\n",
    "        # In practice, you'd modify YOLO's trainer to work with encrypted data\n",
    "        \n",
    "        # Simulate training with privacy noise\n",
    "        original_weights = client_model.model.state_dict() if hasattr(client_model, 'model') else client_model\n",
    "        \n",
    "        # Add differential privacy noise to weights\n",
    "        noisy_weights = {}\n",
    "        for key, weight in original_weights.items():\n",
    "            noise = torch.normal(0, self.noise_multiplier * 0.01, weight.shape)\n",
    "            noisy_weights[key] = weight + noise\n",
    "        \n",
    "        return noisy_weights\n",
    "    \n",
    "    def _create_temp_yolo_config(self, client_id: int) -> str:\n",
    "        \"\"\"Create temporary YOLO config for client training\"\"\"\n",
    "        config = {\n",
    "            'train': f'client_{client_id}_train.txt',\n",
    "            'val': f'client_{client_id}_val.txt', \n",
    "            'nc': 80,  # COCO classes\n",
    "            'names': ['person', 'bicycle', 'car', 'motorcycle', 'airplane']  # Simplified COCO names\n",
    "        }\n",
    "        \n",
    "        config_path = f'temp_client_{client_id}_config.yaml'\n",
    "        \n",
    "        # Only create file if not in demo mode\n",
    "        if not self.demo_mode:\n",
    "            try:\n",
    "                import yaml\n",
    "                with open(config_path, 'w') as f:\n",
    "                    yaml.dump(config, f)\n",
    "            except ImportError:\n",
    "                logger.warning(\"yaml not available, skipping config file creation\")\n",
    "        \n",
    "        return config_path\n",
    "    \n",
    "    def _secure_aggregate(self, client_weights: List[Dict]):\n",
    "        \"\"\"Securely aggregate client weights\"\"\"\n",
    "        if self.demo_mode:\n",
    "            # Simulate secure aggregation\n",
    "            print(\"    Performing secure aggregation with differential privacy...\")\n",
    "            return\n",
    "        \n",
    "        global_weights = self.global_model.model.state_dict() if hasattr(self.global_model, 'model') else self.global_model\n",
    "        \n",
    "        # FedAvg with additional privacy noise\n",
    "        for key in global_weights.keys():\n",
    "            # Average client weights\n",
    "            avg_weight = torch.zeros_like(global_weights[key])\n",
    "            for client_weight in client_weights:\n",
    "                if key in client_weight:\n",
    "                    avg_weight += client_weight[key] / len(client_weights)\n",
    "            \n",
    "            # Add aggregation noise for enhanced privacy\n",
    "            aggregation_noise = torch.normal(0, 0.005, avg_weight.shape)\n",
    "            global_weights[key] = avg_weight + aggregation_noise\n",
    "        \n",
    "        # Update global model\n",
    "        if hasattr(self.global_model, 'model'):\n",
    "            self.global_model.model.load_state_dict(global_weights)\n",
    "        else:\n",
    "            self.global_model = global_weights\n",
    "\n",
    "class YOLOPrivacyAnalyzer:\n",
    "    \"\"\"Analyze privacy guarantees of the YOLO encryption system\"\"\"\n",
    "    \n",
    "    def __init__(self, encryption_system: YOLOImageEncryptionSystem):\n",
    "        self.encryption_system = encryption_system\n",
    "        \n",
    "    def analyze_privacy_leakage(self, original_image: np.ndarray, \n",
    "                               encrypted_image: np.ndarray) -> Dict:\n",
    "        \"\"\"Analyze potential privacy leakage\"\"\"\n",
    "        \n",
    "        # Mutual information estimate (simplified)\n",
    "        mi_estimate = self._estimate_mutual_information(original_image, encrypted_image)\n",
    "        \n",
    "        # Reconstruction attack resistance\n",
    "        attack_resistance = self._test_reconstruction_attack(original_image, encrypted_image)\n",
    "        \n",
    "        # Inference attack analysis\n",
    "        inference_vulnerability = self._analyze_inference_attacks(original_image)\n",
    "        \n",
    "        return {\n",
    "            'mutual_information_estimate': mi_estimate,\n",
    "            'reconstruction_attack_resistance': attack_resistance,\n",
    "            'inference_vulnerability': inference_vulnerability,\n",
    "            'privacy_score': self._calculate_overall_privacy_score(mi_estimate, attack_resistance)\n",
    "        }\n",
    "    \n",
    "    def _estimate_mutual_information(self, img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "        \"\"\"Estimate mutual information between original and encrypted images\"\"\"\n",
    "        # Simplified MI estimation using histogram correlation\n",
    "        hist1 = cv2.calcHist([img1], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])\n",
    "        hist2 = cv2.calcHist([img2], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])\n",
    "        \n",
    "        correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "        return 1.0 - correlation  # Higher values = more privacy\n",
    "    \n",
    "    def _test_reconstruction_attack(self, original: np.ndarray, encrypted: np.ndarray) -> float:\n",
    "        \"\"\"Test resistance to reconstruction attacks\"\"\"\n",
    "        # Simulate simple reconstruction attack\n",
    "        # In practice, use more sophisticated attacks\n",
    "        \n",
    "        mse = np.mean((original.astype(float) - encrypted.astype(float)) ** 2)\n",
    "        max_mse = 255.0 ** 2  # Maximum possible MSE\n",
    "        \n",
    "        resistance_score = mse / max_mse\n",
    "        return min(resistance_score, 1.0)\n",
    "    \n",
    "    def _analyze_inference_attacks(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"Analyze vulnerability to inference attacks\"\"\"\n",
    "        return {\n",
    "            'membership_inference_risk': 'medium',\n",
    "            'attribute_inference_risk': 'low',\n",
    "            'model_inversion_risk': 'high' if image.shape[0] > 512 else 'medium'\n",
    "        }\n",
    "    \n",
    "    def _calculate_overall_privacy_score(self, mi: float, attack_resistance: float) -> float:\n",
    "        \"\"\"Calculate overall privacy score (0-1, higher = more private)\"\"\"\n",
    "        return (mi + attack_resistance) / 2\n",
    "\n",
    "def demo_yolo_privacy_preservation():\n",
    "    \"\"\"Comprehensive demo of privacy-preserving YOLO (standalone demo)\"\"\"\n",
    "    print(\"üîê Privacy-Preserving YOLO Demo (Standalone)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create sample image (simulating a typical YOLO input)\n",
    "    sample_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "    \n",
    "    print(\"1. Initializing Privacy-Preserving YOLO System...\")\n",
    "    \n",
    "    # Setup encryption system\n",
    "    encryption_system = YOLOImageEncryptionSystem()\n",
    "    encryption_system.setup_he_context()\n",
    "    \n",
    "    # Initialize privacy-preserving YOLO (demo mode)\n",
    "    privacy_yolo = PrivacyPreservingYOLO(\"yolov8n-seg.pt\", encryption_system, demo_mode=True)\n",
    "    \n",
    "    print(\"\\n2. Testing different privacy levels...\")\n",
    "    \n",
    "    # Test all privacy levels\n",
    "    for level in [1, 2, 3]:\n",
    "        print(f\"\\n--- Privacy Level {level} ---\")\n",
    "        result = privacy_yolo.encrypt_and_predict(sample_image, privacy_level=level)\n",
    "        \n",
    "        print(f\"Privacy Level: {result['privacy_level']}\")\n",
    "        if 'reconstruction_quality' in result:\n",
    "            quality = result['reconstruction_quality']\n",
    "            print(f\"PSNR: {quality['psnr']:.2f} dB\")\n",
    "            print(f\"SSIM: {quality['ssim']:.3f}\")\n",
    "        \n",
    "        # Show simulated detection results\n",
    "        if 'results' in result:\n",
    "            res = result['results']\n",
    "            print(f\"Detected objects: {res['num_detections']}\")\n",
    "            print(f\"Average confidence: {np.mean(res['confidences']):.3f}\")\n",
    "    \n",
    "    print(\"\\n3. Privacy Analysis...\")\n",
    "    analyzer = YOLOPrivacyAnalyzer(encryption_system)\n",
    "    \n",
    "    # Test with format-preserving encryption\n",
    "    encrypted_l1 = privacy_yolo._format_preserving_encrypt(sample_image)\n",
    "    privacy_analysis = analyzer.analyze_privacy_leakage(sample_image, encrypted_l1)\n",
    "    \n",
    "    print(f\"Privacy Score: {privacy_analysis['privacy_score']:.3f}\")\n",
    "    print(f\"MI Estimate: {privacy_analysis['mutual_information_estimate']:.3f}\")\n",
    "    print(f\"Attack Resistance: {privacy_analysis['reconstruction_attack_resistance']:.3f}\")\n",
    "    \n",
    "    print(\"\\n4. Encryption Performance Metrics...\")\n",
    "    \n",
    "    # Test encryption overhead\n",
    "    import time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    encrypted_data = encryption_system.encrypt_yolo_image(sample_image)\n",
    "    encryption_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Encryption time: {encryption_time:.3f} seconds\")\n",
    "    print(f\"Encrypted tiles: {len(encrypted_data['encrypted_tiles'])}\")\n",
    "    print(f\"Grid shape: {encrypted_data['grid_shape']}\")\n",
    "    \n",
    "    # Test decryption\n",
    "    start_time = time.time()\n",
    "    reconstructed = privacy_yolo._reconstruct_from_encrypted_tiles(encrypted_data)\n",
    "    decryption_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Reconstruction time: {decryption_time:.3f} seconds\")\n",
    "    print(f\"Reconstructed shape: {reconstructed.shape}\")\n",
    "    \n",
    "    print(\"\\nüéØ YOLO Privacy Demo Completed!\")\n",
    "    \n",
    "    return {\n",
    "        'encryption_system': encryption_system,\n",
    "        'privacy_yolo': privacy_yolo,\n",
    "        'sample_results': result\n",
    "    }\n",
    "\n",
    "# Advanced techniques for production deployment\n",
    "class ProductionYOLOPrivacySystem:\n",
    "    \"\"\"Production-ready privacy-preserving YOLO system\"\"\"\n",
    "    \n",
    "    def __init__(self, demo_mode: bool = True):\n",
    "        self.demo_mode = demo_mode\n",
    "        self.encryption_system = YOLOImageEncryptionSystem()\n",
    "        \n",
    "        if not demo_mode and YOLO_AVAILABLE:\n",
    "            self.models = {\n",
    "                'detection': YOLO('yolov8n.pt'),\n",
    "                'segmentation': YOLO('yolov8n-seg.pt'),\n",
    "                'classification': YOLO('yolov8n-cls.pt')\n",
    "            }\n",
    "        else:\n",
    "            # Simulate models for demo\n",
    "            self.models = {\n",
    "                'detection': 'yolov8n.pt',\n",
    "                'segmentation': 'yolov8n-seg.pt', \n",
    "                'classification': 'yolov8n-cls.pt'\n",
    "            }\n",
    "        \n",
    "    def create_privacy_config(self, use_case: str) -> Dict:\n",
    "        \"\"\"Create privacy configuration based on use case\"\"\"\n",
    "        configs = {\n",
    "            'medical_imaging': {\n",
    "                'privacy_level': 3,\n",
    "                'differential_privacy': True,\n",
    "                'federated_learning': True,\n",
    "                'encryption_strength': 'maximum',\n",
    "                'audit_logging': True,\n",
    "                'privacy_budget': 0.5\n",
    "            },\n",
    "            'surveillance': {\n",
    "                'privacy_level': 2,\n",
    "                'differential_privacy': True,\n",
    "                'federated_learning': False,\n",
    "                'encryption_strength': 'high',\n",
    "                'audit_logging': True,\n",
    "                'privacy_budget': 1.0\n",
    "            },\n",
    "            'autonomous_vehicles': {\n",
    "                'privacy_level': 1,\n",
    "                'differential_privacy': False,\n",
    "                'federated_learning': True,\n",
    "                'encryption_strength': 'medium',\n",
    "                'audit_logging': False,\n",
    "                'privacy_budget': 2.0\n",
    "            },\n",
    "            'retail_analytics': {\n",
    "                'privacy_level': 1,\n",
    "                'differential_privacy': True,\n",
    "                'federated_learning': False,\n",
    "                'encryption_strength': 'low',\n",
    "                'audit_logging': True,\n",
    "                'privacy_budget': 1.5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return configs.get(use_case, configs['surveillance'])\n",
    "    \n",
    "    def deploy_privacy_pipeline(self, images: List[np.ndarray], \n",
    "                              use_case: str, task: str = 'detection') -> List[Dict]:\n",
    "        \"\"\"Deploy complete privacy-preserving pipeline\"\"\"\n",
    "        config = self.create_privacy_config(use_case)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, image in enumerate(tqdm(images, desc=f\"Processing {task}\")):\n",
    "            # Apply privacy configuration\n",
    "            if config['privacy_level'] >= 2:\n",
    "                self.encryption_system.setup_he_context()\n",
    "            \n",
    "            # Get privacy-preserving YOLO\n",
    "            privacy_yolo = PrivacyPreservingYOLO(\n",
    "                model_path=self.models[task],\n",
    "                encryption_system=self.encryption_system,\n",
    "                demo_mode=self.demo_mode\n",
    "            )\n",
    "            \n",
    "            # Run encrypted inference\n",
    "            result = privacy_yolo.encrypt_and_predict(\n",
    "                image, privacy_level=config['privacy_level']\n",
    "            )\n",
    "            \n",
    "            # Add privacy audit info\n",
    "            result.update({\n",
    "                'use_case': use_case,\n",
    "                'privacy_config': config,\n",
    "                'image_id': i,\n",
    "                'audit_timestamp': time.time()\n",
    "            })\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f9f20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setting up CKKS context for YOLO...\n",
      "INFO:__main__:CKKS context initialized for YOLO processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running Privacy-Preserving YOLO Demo\n",
      "This demo shows how to integrate homomorphic encryption with YOLO models\n",
      "\n",
      "üîê Privacy-Preserving YOLO Demo (Standalone)\n",
      "============================================================\n",
      "1. Initializing Privacy-Preserving YOLO System...\n",
      "\n",
      "2. Testing different privacy levels...\n",
      "\n",
      "--- Privacy Level 1 ---\n",
      "Privacy Level: 1\n",
      "Detected objects: 3\n",
      "Average confidence: 0.763\n",
      "\n",
      "--- Privacy Level 2 ---\n",
      "Privacy Level: 2\n",
      "PSNR: 10.78 dB\n",
      "SSIM: 0.023\n",
      "Detected objects: 2\n",
      "Average confidence: 0.945\n",
      "\n",
      "--- Privacy Level 3 ---\n",
      "Privacy Level: 3\n",
      "Detected objects: 3\n",
      "Average confidence: 0.458\n",
      "\n",
      "3. Privacy Analysis...\n",
      "Privacy Score: 1.084\n",
      "MI Estimate: 2.003\n",
      "Attack Resistance: 0.166\n",
      "\n",
      "4. Encryption Performance Metrics...\n",
      "Encryption time: 0.626 seconds\n",
      "Encrypted tiles: 64\n",
      "Grid shape: (8, 8)\n",
      "Reconstruction time: 0.175 seconds\n",
      "Reconstructed shape: (640, 640, 3)\n",
      "\n",
      "üéØ YOLO Privacy Demo Completed!\n",
      "\n",
      "============================================================\n",
      "WHEN YOU HAVE A DATASET - PRACTICAL EXAMPLES:\n",
      "============================================================\n",
      "\n",
      "üìÅ Dataset Preparation:\n",
      "\n",
      "# 1. Organize your dataset in YOLO format:\n",
      "dataset/\n",
      "  ‚îú‚îÄ‚îÄ images/\n",
      "  ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
      "  ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
      "  ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
      "  ‚îî‚îÄ‚îÄ labels/\n",
      "      ‚îú‚îÄ‚îÄ train/\n",
      "      ‚îú‚îÄ‚îÄ val/ \n",
      "      ‚îî‚îÄ‚îÄ test/\n",
      "\n",
      "# 2. Each label file should contain:\n",
      "# class_id x_center y_center width height [polygon_points...]\n",
      "# Example: 0 0.5 0.3 0.2 0.4  # person at center-left\n",
      "\n",
      "\n",
      "üîß Real Implementation Example:\n",
      "\n",
      "# Install required packages:\n",
      "# pip install ultralytics tenseal cryptography opencv-python\n",
      "\n",
      "from ultralytics import YOLO\n",
      "import cv2\n",
      "\n",
      "# 1. Load your YOLO model\n",
      "model_path = \"yolov8n-seg.pt\"  # or your custom trained model\n",
      "encryption_system = YOLOImageEncryptionSystem()\n",
      "\n",
      "# 2. Initialize privacy-preserving YOLO\n",
      "privacy_yolo = PrivacyPreservingYOLO(model_path, encryption_system, demo_mode=False)\n",
      "\n",
      "# 3. Process your images\n",
      "image_path = \"path/to/your/image.jpg\"\n",
      "image = cv2.imread(image_path)\n",
      "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
      "\n",
      "# 4. Run encrypted inference\n",
      "result = privacy_yolo.encrypt_and_predict(\n",
      "    image, \n",
      "    confidence=0.25,\n",
      "    privacy_level=2  # Choose based on your privacy needs\n",
      ")\n",
      "\n",
      "# 5. Access results\n",
      "if not privacy_yolo.demo_mode:\n",
      "    yolo_results = result['results'][0]\n",
      "    \n",
      "    # Bounding boxes\n",
      "    boxes = yolo_results.boxes.xyxy.cpu().numpy()  # x1,y1,x2,y2 format\n",
      "    confidences = yolo_results.boxes.conf.cpu().numpy()\n",
      "    class_ids = yolo_results.boxes.cls.cpu().numpy()\n",
      "    \n",
      "    # Segmentation masks (if using seg model)\n",
      "    if hasattr(yolo_results, 'masks') and yolo_results.masks is not None:\n",
      "        masks = yolo_results.masks.data.cpu().numpy()\n",
      "    \n",
      "    print(f\"Found {len(boxes)} objects\")\n",
      "    for i, (box, conf, cls) in enumerate(zip(boxes, confidences, class_ids)):\n",
      "        print(f\"Object {i}: Class {int(cls)}, Confidence {conf:.3f}, Box {box}\")\n",
      "\n",
      "\n",
      "üè≠ Training Your Own Privacy-Preserving Model:\n",
      "\n",
      "# 1. Setup federated training\n",
      "fed_trainer = FederatedYOLOTrainer(\"path/to/your/yolo_config.yaml\", num_clients=5, demo_mode=False)\n",
      "\n",
      "# 2. Prepare client data splits\n",
      "client_data_splits = [\n",
      "    {\n",
      "        'images': ['client1_images/*.jpg'],\n",
      "        'annotations': ['client1_labels/*.txt']\n",
      "    },\n",
      "    # ... more clients\n",
      "]\n",
      "\n",
      "fed_trainer.setup_client_data(client_data_splits)\n",
      "\n",
      "# 3. Run federated training rounds\n",
      "for round_num in range(100):\n",
      "    results = fed_trainer.train_federated_round(round_num, local_epochs=5)\n",
      "    print(f\"Round {round_num}: Privacy budget used: {results.get('privacy_budget_used', 0.1)}\")\n",
      "    \n",
      "    # Monitor privacy budget\n",
      "    if fed_trainer.privacy_budget <= 0.1:\n",
      "        print(\"Privacy budget exhausted, stopping training\")\n",
      "        break\n",
      "\n",
      "\n",
      "üîí Privacy Configuration Guide:\n",
      "\n",
      "# Choose privacy level based on your use case:\n",
      "\n",
      "# Medical/Healthcare Images (Maximum Privacy)\n",
      "config = {\n",
      "    'privacy_level': 3,           # Full homomorphic encryption\n",
      "    'differential_privacy': True,\n",
      "    'privacy_budget': 0.5,       # Strict budget\n",
      "    'federated_learning': True,\n",
      "    'secure_aggregation': True\n",
      "}\n",
      "\n",
      "# Surveillance/Security (Balanced)\n",
      "config = {\n",
      "    'privacy_level': 2,           # Hybrid encryption\n",
      "    'differential_privacy': True,\n",
      "    'privacy_budget': 1.0,\n",
      "    'federated_learning': True,\n",
      "    'secure_aggregation': False\n",
      "}\n",
      "\n",
      "# Research/Development (Performance Priority)\n",
      "config = {\n",
      "    'privacy_level': 1,           # Format-preserving\n",
      "    'differential_privacy': False,\n",
      "    'privacy_budget': 2.0,\n",
      "    'federated_learning': False,\n",
      "    'secure_aggregation': False\n",
      "}\n",
      "\n",
      "\n",
      "‚ö° Performance Benchmarks (Expected):\n",
      "Privacy Level 1: ~5% overhead, 95% accuracy retention\n",
      "Privacy Level 2: ~50% overhead, 85% accuracy retention\n",
      "Privacy Level 3: ~10x overhead, 70% accuracy retention\n",
      "\n",
      "‚úÖ Next Steps:\n",
      "1. Install ultralytics: pip install ultralytics\n",
      "2. Prepare your dataset in YOLO format\n",
      "3. Choose appropriate privacy level for your use case\n",
      "4. Run training with privacy_yolo.encrypt_and_predict()\n",
      "5. Monitor privacy budget and model performance\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Running Privacy-Preserving YOLO Demo\")\n",
    "    print(\"This demo shows how to integrate homomorphic encryption with YOLO models\")\n",
    "    print()\n",
    "    \n",
    "    # Run the demo (now works without ultralytics)\n",
    "    demo_results = demo_yolo_privacy_preservation()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"WHEN YOU HAVE A DATASET - PRACTICAL EXAMPLES:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüìÅ Dataset Preparation:\")\n",
    "    print(\"\"\"\n",
    "# 1. Organize your dataset in YOLO format:\n",
    "dataset/\n",
    "  ‚îú‚îÄ‚îÄ images/\n",
    "  ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "  ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "  ‚îî‚îÄ‚îÄ labels/\n",
    "      ‚îú‚îÄ‚îÄ train/\n",
    "      ‚îú‚îÄ‚îÄ val/ \n",
    "      ‚îî‚îÄ‚îÄ test/\n",
    "\n",
    "# 2. Each label file should contain:\n",
    "# class_id x_center y_center width height [polygon_points...]\n",
    "# Example: 0 0.5 0.3 0.2 0.4  # person at center-left\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nüîß Real Implementation Example:\")\n",
    "    print(\"\"\"\n",
    "# Install required packages:\n",
    "# pip install ultralytics tenseal cryptography opencv-python\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# 1. Load your YOLO model\n",
    "model_path = \"yolov8n-seg.pt\"  # or your custom trained model\n",
    "encryption_system = YOLOImageEncryptionSystem()\n",
    "\n",
    "# 2. Initialize privacy-preserving YOLO\n",
    "privacy_yolo = PrivacyPreservingYOLO(model_path, encryption_system, demo_mode=False)\n",
    "\n",
    "# 3. Process your images\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 4. Run encrypted inference\n",
    "result = privacy_yolo.encrypt_and_predict(\n",
    "    image, \n",
    "    confidence=0.25,\n",
    "    privacy_level=2  # Choose based on your privacy needs\n",
    ")\n",
    "\n",
    "# 5. Access results\n",
    "if not privacy_yolo.demo_mode:\n",
    "    yolo_results = result['results'][0]\n",
    "    \n",
    "    # Bounding boxes\n",
    "    boxes = yolo_results.boxes.xyxy.cpu().numpy()  # x1,y1,x2,y2 format\n",
    "    confidences = yolo_results.boxes.conf.cpu().numpy()\n",
    "    class_ids = yolo_results.boxes.cls.cpu().numpy()\n",
    "    \n",
    "    # Segmentation masks (if using seg model)\n",
    "    if hasattr(yolo_results, 'masks') and yolo_results.masks is not None:\n",
    "        masks = yolo_results.masks.data.cpu().numpy()\n",
    "    \n",
    "    print(f\"Found {len(boxes)} objects\")\n",
    "    for i, (box, conf, cls) in enumerate(zip(boxes, confidences, class_ids)):\n",
    "        print(f\"Object {i}: Class {int(cls)}, Confidence {conf:.3f}, Box {box}\")\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nüè≠ Training Your Own Privacy-Preserving Model:\")\n",
    "    print(\"\"\"\n",
    "# 1. Setup federated training\n",
    "fed_trainer = FederatedYOLOTrainer(\"path/to/your/yolo_config.yaml\", num_clients=5, demo_mode=False)\n",
    "\n",
    "# 2. Prepare client data splits\n",
    "client_data_splits = [\n",
    "    {\n",
    "        'images': ['client1_images/*.jpg'],\n",
    "        'annotations': ['client1_labels/*.txt']\n",
    "    },\n",
    "    # ... more clients\n",
    "]\n",
    "\n",
    "fed_trainer.setup_client_data(client_data_splits)\n",
    "\n",
    "# 3. Run federated training rounds\n",
    "for round_num in range(100):\n",
    "    results = fed_trainer.train_federated_round(round_num, local_epochs=5)\n",
    "    print(f\"Round {round_num}: Privacy budget used: {results.get('privacy_budget_used', 0.1)}\")\n",
    "    \n",
    "    # Monitor privacy budget\n",
    "    if fed_trainer.privacy_budget <= 0.1:\n",
    "        print(\"Privacy budget exhausted, stopping training\")\n",
    "        break\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nüîí Privacy Configuration Guide:\")\n",
    "    print(\"\"\"\n",
    "# Choose privacy level based on your use case:\n",
    "\n",
    "# Medical/Healthcare Images (Maximum Privacy)\n",
    "config = {\n",
    "    'privacy_level': 3,           # Full homomorphic encryption\n",
    "    'differential_privacy': True,\n",
    "    'privacy_budget': 0.5,       # Strict budget\n",
    "    'federated_learning': True,\n",
    "    'secure_aggregation': True\n",
    "}\n",
    "\n",
    "# Surveillance/Security (Balanced)\n",
    "config = {\n",
    "    'privacy_level': 2,           # Hybrid encryption\n",
    "    'differential_privacy': True,\n",
    "    'privacy_budget': 1.0,\n",
    "    'federated_learning': True,\n",
    "    'secure_aggregation': False\n",
    "}\n",
    "\n",
    "# Research/Development (Performance Priority)\n",
    "config = {\n",
    "    'privacy_level': 1,           # Format-preserving\n",
    "    'differential_privacy': False,\n",
    "    'privacy_budget': 2.0,\n",
    "    'federated_learning': False,\n",
    "    'secure_aggregation': False\n",
    "}\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\n‚ö° Performance Benchmarks (Expected):\")\n",
    "    print(\"Privacy Level 1: ~5% overhead, 95% accuracy retention\")\n",
    "    print(\"Privacy Level 2: ~50% overhead, 85% accuracy retention\") \n",
    "    print(\"Privacy Level 3: ~10x overhead, 70% accuracy retention\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Next Steps:\")\n",
    "    print(\"1. Install ultralytics: pip install ultralytics\")\n",
    "    print(\"2. Prepare your dataset in YOLO format\")  \n",
    "    print(\"3. Choose appropriate privacy level for your use case\")\n",
    "    print(\"4. Run training with privacy_yolo.encrypt_and_predict()\")\n",
    "    print(\"5. Monitor privacy budget and model performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13322ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b1a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a92e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tenseal as ts\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import hashlib\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    import albumentations as A\n",
    "except ImportError:\n",
    "    print(\"albumentations not installed, using basic transforms\")\n",
    "    A = None\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Ultralytics YOLO imports (optional for demo)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    from ultralytics.models.yolo.segment import SegmentationTrainer\n",
    "    from ultralytics.models.yolo.detect import DetectionTrainer\n",
    "    from ultralytics.utils import ops\n",
    "    import yaml\n",
    "    YOLO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Ultralytics YOLO not installed - running in demo mode\")\n",
    "    YOLO_AVAILABLE = False\n",
    "    \n",
    "    # Create dummy YOLO class for demo\n",
    "    class YOLO:\n",
    "        def __init__(self, model_path):\n",
    "            self.ckpt_path = model_path\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            return \"simulated_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ccdeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class YOLOHEConfig:\n",
    "    \"\"\"Configuration for YOLO homomorphic encryption\"\"\"\n",
    "    poly_modulus_degree: int = 16384\n",
    "    coeff_mod_bit_sizes: List[int] = None\n",
    "    scale: float = 2.0**30\n",
    "    yolo_input_size: int = 640  # Standard YOLO input size\n",
    "    tile_size: Tuple[int, int] = (80, 80)  # Divide 640x640 into 8x8 tiles\n",
    "    compression_ratio: float = 0.05  # Heavy compression for HE\n",
    "    preserve_aspect_ratio: bool = True\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.coeff_mod_bit_sizes is None:\n",
    "            self.coeff_mod_bit_sizes = [60, 40, 40, 40, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54330a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOImageEncryptionSystem:\n",
    "    \"\"\"Specialized encryption system for YOLO models\"\"\"\n",
    "    \n",
    "    def __init__(self, config: YOLOHEConfig = None):\n",
    "        self.config = config or YOLOHEConfig()\n",
    "        self.he_context = None\n",
    "        self.encryption_mappings = {}\n",
    "        self.fernet_key = Fernet.generate_key()\n",
    "        self.fernet = Fernet(self.fernet_key)\n",
    "        \n",
    "    def setup_he_context(self) -> ts.Context:\n",
    "        \"\"\"Initialize CKKS context optimized for YOLO images\"\"\"\n",
    "        logger.info(\"Setting up CKKS context for YOLO...\")\n",
    "        \n",
    "        context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=self.config.poly_modulus_degree,\n",
    "            coeff_mod_bit_sizes=self.config.coeff_mod_bit_sizes\n",
    "        )\n",
    "        \n",
    "        context.generate_galois_keys()\n",
    "        context.generate_relin_keys()\n",
    "        context.global_scale = self.config.scale\n",
    "        \n",
    "        self.he_context = context\n",
    "        logger.info(\"CKKS context initialized for YOLO processing\")\n",
    "        return context\n",
    "    \n",
    "    def encrypt_yolo_image(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"Encrypt image for YOLO processing\"\"\"\n",
    "        if not self.he_context:\n",
    "            self.setup_he_context()\n",
    "        \n",
    "        # Ensure image is YOLO size\n",
    "        target_size = self.config.yolo_input_size\n",
    "        if image.shape[:2] != (target_size, target_size):\n",
    "            image = cv2.resize(image, (target_size, target_size))\n",
    "        \n",
    "        # Split into tiles\n",
    "        tiles = self._split_into_yolo_tiles(image)\n",
    "        \n",
    "        # Encrypt each tile\n",
    "        encrypted_tiles = []\n",
    "        metadata = []\n",
    "        \n",
    "        for i, tile in enumerate(tiles):\n",
    "            # Extract features and compress\n",
    "            features = self._extract_tile_features(tile)\n",
    "            \n",
    "            # Encrypt with CKKS\n",
    "            encrypted_vector = ts.ckks_vector(self.he_context, features)\n",
    "            serialized = encrypted_vector.serialize()\n",
    "            \n",
    "            encrypted_tiles.append(serialized)\n",
    "            metadata.append({\n",
    "                'tile_id': i,\n",
    "                'position': self._get_tile_position(i),\n",
    "                'feature_dim': len(features)\n",
    "            })\n",
    "        \n",
    "        grid_h = target_size // self.config.tile_size[0]\n",
    "        grid_w = target_size // self.config.tile_size[1]\n",
    "        \n",
    "        return {\n",
    "            'encrypted_tiles': encrypted_tiles,\n",
    "            'grid_shape': (grid_h, grid_w),\n",
    "            'metadata': metadata,\n",
    "            'encryption_id': hashlib.md5(str(tiles).encode()).hexdigest()[:16]\n",
    "        }\n",
    "    \n",
    "    def _split_into_yolo_tiles(self, image: np.ndarray) -> List[np.ndarray]:\n",
    "        \"\"\"Split YOLO-sized image into tiles\"\"\"\n",
    "        h, w, c = image.shape\n",
    "        tile_h, tile_w = self.config.tile_size\n",
    "        \n",
    "        tiles = []\n",
    "        for i in range(0, h, tile_h):\n",
    "            for j in range(0, w, tile_w):\n",
    "                tile = image[i:i+tile_h, j:j+tile_w]\n",
    "                \n",
    "                # Pad if necessary (edge tiles)\n",
    "                if tile.shape[0] < tile_h or tile.shape[1] < tile_w:\n",
    "                    padded_tile = np.zeros((tile_h, tile_w, c), dtype=image.dtype)\n",
    "                    padded_tile[:tile.shape[0], :tile.shape[1]] = tile\n",
    "                    tile = padded_tile\n",
    "                \n",
    "                tiles.append(tile)\n",
    "        \n",
    "        return tiles\n",
    "    \n",
    "    def _get_tile_position(self, tile_idx: int) -> Tuple[int, int]:\n",
    "        \"\"\"Get grid position of tile\"\"\"\n",
    "        grid_w = self.config.yolo_input_size // self.config.tile_size[1]\n",
    "        row = tile_idx // grid_w\n",
    "        col = tile_idx % grid_w\n",
    "        return (row, col)\n",
    "    \n",
    "    def _extract_tile_features(self, tile: np.ndarray) -> List[float]:\n",
    "        \"\"\"Extract features from tile for HE (optimized for YOLO)\"\"\"\n",
    "        # Ensure proper data type for OpenCV\n",
    "        tile = tile.astype(np.uint8)\n",
    "        features = []\n",
    "        \n",
    "        # Color channel statistics\n",
    "        for c in range(min(3, tile.shape[2])):  # Handle grayscale or RGB\n",
    "            channel = tile[:, :, c] if len(tile.shape) == 3 else tile\n",
    "            features.extend([\n",
    "                float(np.mean(channel)) / 255.0,\n",
    "                float(np.std(channel)) / 255.0,\n",
    "                float(np.median(channel)) / 255.0\n",
    "            ])\n",
    "        \n",
    "        # Convert to grayscale safely\n",
    "        if len(tile.shape) == 3 and tile.shape[2] == 3:\n",
    "            gray = cv2.cvtColor(tile, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = tile if len(tile.shape) == 2 else tile[:, :, 0]\n",
    "        \n",
    "        gray = gray.astype(np.uint8)\n",
    "        \n",
    "        # Edge features (important for object detection)\n",
    "        try:\n",
    "            edges = cv2.Canny(gray, 50, 150)\n",
    "            edge_density = float(np.sum(edges > 0)) / edges.size\n",
    "            features.append(edge_density)\n",
    "        except:\n",
    "            features.append(0.0)  # Fallback\n",
    "        \n",
    "        # Corner features\n",
    "        try:\n",
    "            corners = cv2.goodFeaturesToTrack(gray, 25, 0.01, 10)\n",
    "            corner_count = len(corners) if corners is not None else 0\n",
    "            features.append(float(corner_count) / 25.0)  # Normalize\n",
    "        except:\n",
    "            features.append(0.0)  # Fallback\n",
    "        \n",
    "        # Texture features (simplified)\n",
    "        try:\n",
    "            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            texture_strength = float(np.mean(np.sqrt(grad_x**2 + grad_y**2))) / 255.0\n",
    "            features.append(texture_strength)\n",
    "        except:\n",
    "            features.append(0.0)  # Fallback\n",
    "        \n",
    "        # Apply compression\n",
    "        compression_step = max(1, int(1 / self.config.compression_ratio))\n",
    "        if len(features) > compression_step:\n",
    "            features = features[::compression_step]\n",
    "        \n",
    "        return features\n",
    "\n",
    "class PrivacyPreservingYOLO:\n",
    "    \"\"\"Privacy-preserving wrapper for YOLO models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = \"yolov8n-seg.pt\", \n",
    "                 encryption_system: YOLOImageEncryptionSystem = None, \n",
    "                 demo_mode: bool = True):\n",
    "        self.model_path = model_path\n",
    "        self.demo_mode = demo_mode\n",
    "        self.encryption_system = encryption_system or YOLOImageEncryptionSystem()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize YOLO model (or simulate for demo)\n",
    "        if not demo_mode:\n",
    "            try:\n",
    "                self.model = YOLO(model_path)\n",
    "            except ImportError:\n",
    "                logger.warning(\"Ultralytics not installed, running in demo mode\")\n",
    "                self.demo_mode = True\n",
    "                self.model = None\n",
    "        else:\n",
    "            self.model = None\n",
    "        \n",
    "        # Privacy-preserving adapter network\n",
    "        self.privacy_adapter = self._build_privacy_adapter()\n",
    "        \n",
    "    def _build_privacy_adapter(self) -> nn.Module:\n",
    "        \"\"\"Build adapter network to process encrypted features\"\"\"\n",
    "        # Estimate feature dimension from encryption system\n",
    "        dummy_tile = np.random.randint(0, 255, (*self.encryption_system.config.tile_size, 3))\n",
    "        feature_dim = len(self.encryption_system._extract_tile_features(dummy_tile))\n",
    "        \n",
    "        adapter = nn.Sequential(\n",
    "            # Decrypt and process encrypted features\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Map to YOLO-compatible features\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            # Output layer (maps to RGB tile representation)\n",
    "            nn.Linear(512, self.encryption_system.config.tile_size[0] * \n",
    "                           self.encryption_system.config.tile_size[1] * 3),\n",
    "            nn.Sigmoid()  # Normalize to [0,1]\n",
    "        )\n",
    "        \n",
    "        return adapter.to(self.device)\n",
    "    \n",
    "    def encrypt_and_predict(self, image: np.ndarray, confidence: float = 0.25, \n",
    "                           privacy_level: int = 2) -> Dict:\n",
    "        \"\"\"Perform YOLO prediction on encrypted image\"\"\"\n",
    "        \n",
    "        if privacy_level == 1:\n",
    "            # Level 1: Light encryption with direct YOLO inference\n",
    "            return self._predict_level_1(image, confidence)\n",
    "        elif privacy_level == 2:\n",
    "            # Level 2: Feature encryption with adapter network\n",
    "            return self._predict_level_2(image, confidence)\n",
    "        else:\n",
    "            # Level 3: Full homomorphic encryption\n",
    "            return self._predict_level_3(image, confidence)\n",
    "    \n",
    "    def _predict_level_3(self, image: np.ndarray, confidence: float) -> Dict:\n",
    "        \"\"\"Level 3: Full homomorphic encryption with secure computation\"\"\"\n",
    "        # This is the most complex case - simplified implementation\n",
    "        encrypted_data = self.encryption_system.encrypt_yolo_image(image)\n",
    "        \n",
    "        # In a real implementation, you'd perform homomorphic operations\n",
    "        # on the encrypted features to compute YOLO-like outputs\n",
    "        # For demo, we'll decrypt for inference but track privacy cost\n",
    "        \n",
    "        reconstructed_image = self._reconstruct_from_encrypted_tiles(encrypted_data)\n",
    "        \n",
    "        if self.demo_mode:\n",
    "            results = self._simulate_yolo_results(reconstructed_image.shape)\n",
    "        else:\n",
    "            results = self.model(reconstructed_image, conf=confidence, verbose=False)\n",
    "        \n",
    "        return {\n",
    "            'privacy_level': 3,\n",
    "            'results': results,\n",
    "            'privacy_cost': 'high',\n",
    "            'secure_computation': True,\n",
    "            'encrypted_inference': True\n",
    "        }\n",
    "    \n",
    "    def _simulate_yolo_results(self, image_shape: Tuple[int, int, int]) -> Dict:\n",
    "        \"\"\"Simulate YOLO results for demo purposes\"\"\"\n",
    "        h, w, c = image_shape\n",
    "        num_detections = np.random.randint(1, 5)\n",
    "        \n",
    "        # Simulate bounding boxes\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for _ in range(num_detections):\n",
    "            x1 = np.random.randint(0, w//2)\n",
    "            y1 = np.random.randint(0, h//2)\n",
    "            x2 = np.random.randint(x1 + 20, w)\n",
    "            y2 = np.random.randint(y1 + 20, h)\n",
    "            \n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            confidences.append(np.random.random() * 0.7 + 0.3)  # 0.3-1.0\n",
    "            class_ids.append(np.random.randint(0, 80))  # COCO has 80 classes\n",
    "        \n",
    "        # Simulate segmentation masks\n",
    "        masks = []\n",
    "        for bbox in boxes:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            # Create simple elliptical mask in bbox\n",
    "            center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            axes = ((x2 - x1) // 2, (y2 - y1) // 2)\n",
    "            cv2.ellipse(mask, (center_x, center_y), axes, 0, 0, 360, 255, -1)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        return {\n",
    "            'boxes': np.array(boxes),\n",
    "            'confidences': np.array(confidences),\n",
    "            'class_ids': np.array(class_ids),\n",
    "            'masks': masks,\n",
    "            'num_detections': num_detections\n",
    "        }\n",
    "    \n",
    "    def _format_preserving_encrypt(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Simple format-preserving encryption via pixel permutation\"\"\"\n",
    "        h, w, c = image.shape\n",
    "        \n",
    "        # Create deterministic permutation based on secret key\n",
    "        np.random.seed(42)  # In production, use actual secret key\n",
    "        \n",
    "        encrypted_image = image.copy()\n",
    "        for channel in range(c):\n",
    "            flat_channel = encrypted_image[:, :, channel].flatten()\n",
    "            perm_indices = np.random.permutation(len(flat_channel))\n",
    "            encrypted_image[:, :, channel] = flat_channel[perm_indices].reshape(h, w)\n",
    "        \n",
    "        return encrypted_image\n",
    "    \n",
    "    def _reconstruct_from_encrypted_tiles(self, encrypted_data: Dict) -> np.ndarray:\n",
    "        \"\"\"Reconstruct image from encrypted tiles using adapter network\"\"\"\n",
    "        encrypted_tiles = encrypted_data['encrypted_tiles']\n",
    "        grid_shape = encrypted_data['grid_shape']\n",
    "        \n",
    "        self.privacy_adapter.eval()\n",
    "        reconstructed_tiles = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for encrypted_tile_data in encrypted_tiles:\n",
    "                # Decrypt tile features\n",
    "                encrypted_vector = ts.lazy_ckks_vector_from(encrypted_tile_data)\n",
    "                encrypted_vector.link_context(self.encryption_system.he_context)\n",
    "                decrypted_features = encrypted_vector.decrypt()\n",
    "                \n",
    "                # Convert to tensor and process through adapter\n",
    "                feature_tensor = torch.FloatTensor(decrypted_features).unsqueeze(0).to(self.device)\n",
    "                reconstructed_flat = self.privacy_adapter(feature_tensor)\n",
    "                \n",
    "                # Reshape to tile\n",
    "                tile_h, tile_w = self.encryption_system.config.tile_size\n",
    "                reconstructed_tile = reconstructed_flat.view(tile_h, tile_w, 3)\n",
    "                reconstructed_tile = (reconstructed_tile * 255).cpu().numpy().astype(np.uint8)\n",
    "                reconstructed_tiles.append(reconstructed_tile)\n",
    "        \n",
    "        # Reassemble tiles into full image\n",
    "        return self._assemble_tiles(reconstructed_tiles, grid_shape)\n",
    "    \n",
    "    def _assemble_tiles(self, tiles: List[np.ndarray], grid_shape: Tuple[int, int]) -> np.ndarray:\n",
    "        \"\"\"Reassemble tiles into full image\"\"\"\n",
    "        grid_h, grid_w = grid_shape\n",
    "        tile_h, tile_w = self.encryption_system.config.tile_size\n",
    "        \n",
    "        full_image = np.zeros((grid_h * tile_h, grid_w * tile_w, 3), dtype=np.uint8)\n",
    "        \n",
    "        for idx, tile in enumerate(tiles):\n",
    "            row = idx // grid_w\n",
    "            col = idx % grid_w\n",
    "            \n",
    "            start_h = row * tile_h\n",
    "            start_w = col * tile_w\n",
    "            \n",
    "            full_image[start_h:start_h+tile_h, start_w:start_w+tile_w] = tile\n",
    "        \n",
    "        # Crop to YOLO input size if needed\n",
    "        target_size = self.encryption_system.config.yolo_input_size\n",
    "        return full_image[:target_size, :target_size]\n",
    "    \n",
    "    def _calculate_reconstruction_quality(self, original: np.ndarray, \n",
    "                                        reconstructed: np.ndarray) -> Dict:\n",
    "        \"\"\"Calculate reconstruction quality metrics\"\"\"\n",
    "        # Resize reconstructed to match original if needed\n",
    "        if original.shape != reconstructed.shape:\n",
    "            reconstructed = cv2.resize(reconstructed, (original.shape[1], original.shape[0]))\n",
    "        \n",
    "        mse = np.mean((original.astype(float) - reconstructed.astype(float)) ** 2)\n",
    "        psnr = 20 * np.log10(255.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "        \n",
    "        return {\n",
    "            'mse': float(mse),\n",
    "            'psnr': float(psnr),\n",
    "            'ssim': self._calculate_ssim(original, reconstructed)\n",
    "        }\n",
    "    \n",
    "    def _calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "        \"\"\"Calculate SSIM (simplified version)\"\"\"\n",
    "        # Convert to grayscale safely\n",
    "        if len(img1.shape) == 3:\n",
    "            gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "            gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray1, gray2 = img1, img2\n",
    "        \n",
    "        # Calculate means\n",
    "        mu1 = np.mean(gray1)\n",
    "        mu2 = np.mean(gray2)\n",
    "        \n",
    "        # Calculate variances and covariance\n",
    "        var1 = np.var(gray1)\n",
    "        var2 = np.var(gray2)\n",
    "        covar = np.mean((gray1 - mu1) * (gray2 - mu2))\n",
    "        \n",
    "        # SSIM calculation\n",
    "        c1 = (0.01 * 255) ** 2\n",
    "        c2 = (0.03 * 255) ** 2\n",
    "        \n",
    "        ssim = ((2 * mu1 * mu2 + c1) * (2 * covar + c2)) / \\\n",
    "               ((mu1**2 + mu2**2 + c1) * (var1 + var2 + c2))\n",
    "        \n",
    "        return float(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1117db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encryption_system = YOLOImageEncryptionSystem()\n",
    "\n",
    "privacy_yolo = PrivacyPreservingYOLO(\n",
    "    model_path=\"./TRAINING/runs/segment/train3/weights/best.pt\",\n",
    "    encryption_system=encryption_system,\n",
    "    demo_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ba6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
